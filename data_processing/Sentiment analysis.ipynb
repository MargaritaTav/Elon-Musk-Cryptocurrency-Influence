{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4697b5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fb902b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gunja\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\gunja\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gunja\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\gunja\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\gunja\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>MESSAGE</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Please ignore prior tweets, as that was someon...</td>\n",
       "      <td>2010-06-04 18:31:57+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Went to Iceland on Sat to ride bumper cars on ...</td>\n",
       "      <td>2011-12-01 09:55:11+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>I made the volume on the Model S http://ow.ly/...</td>\n",
       "      <td>2011-12-01 10:29:04+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Great Voltaire quote, arguably better than Twa...</td>\n",
       "      <td>2011-12-03 08:20:28+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>That was a total non sequitur btw\\n26\\n14\\n50</td>\n",
       "      <td>2011-12-03 08:22:07+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            MESSAGE  \\\n",
       "0           0  Please ignore prior tweets, as that was someon...   \n",
       "1           1  Went to Iceland on Sat to ride bumper cars on ...   \n",
       "2           2  I made the volume on the Model S http://ow.ly/...   \n",
       "3           3  Great Voltaire quote, arguably better than Twa...   \n",
       "4           4      That was a total non sequitur btw\\n26\\n14\\n50   \n",
       "\n",
       "                        date  \n",
       "0  2010-06-04 18:31:57+00:00  \n",
       "1  2011-12-01 09:55:11+00:00  \n",
       "2  2011-12-01 10:29:04+00:00  \n",
       "3  2011-12-03 08:20:28+00:00  \n",
       "4  2011-12-03 08:22:07+00:00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\gunja\\OneDrive\\Desktop\\DEDA PROJECT\\musktweets.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7ff6f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MESSAGE</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>please ignore prior tweet someone pretending a...</td>\n",
       "      <td>2010-06-04 18:31:57+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>went iceland sat ride bumper car ice country v...</td>\n",
       "      <td>2011-12-01 09:55:11+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>made volume model go need work miniature stone...</td>\n",
       "      <td>2011-12-01 10:29:04+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>great voltaire quote arguably better twain hea...</td>\n",
       "      <td>2011-12-03 08:20:28+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>total non sequitur btw</td>\n",
       "      <td>2011-12-03 08:22:07+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             MESSAGE  \\\n",
       "0  please ignore prior tweet someone pretending a...   \n",
       "1  went iceland sat ride bumper car ice country v...   \n",
       "2  made volume model go need work miniature stone...   \n",
       "3  great voltaire quote arguably better twain hea...   \n",
       "4                             total non sequitur btw   \n",
       "\n",
       "                        date  \n",
       "0  2010-06-04 18:31:57+00:00  \n",
       "1  2011-12-01 09:55:11+00:00  \n",
       "2  2011-12-01 10:29:04+00:00  \n",
       "3  2011-12-03 08:20:28+00:00  \n",
       "4  2011-12-03 08:22:07+00:00  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data cleaning\n",
    "\n",
    "df = df[['MESSAGE', 'date']]\n",
    "\n",
    "df['MESSAGE'] = df['MESSAGE'].str.lower()\n",
    "\n",
    "df['MESSAGE'] = df['MESSAGE'].apply(lambda x: re.sub(r\"(http\\S+|www\\S+|@\\S+)\", \"\", str(x)))\n",
    "\n",
    "df['MESSAGE'] = df['MESSAGE'].apply(lambda x: re.sub(r\"[^a-zA-Z\\s]\", \"\", str(x)))\n",
    "\n",
    "df['MESSAGE'] = df['MESSAGE'].apply(lambda x: nltk.word_tokenize(str(x)))\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['MESSAGE'] = df['MESSAGE'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in text]\n",
    "    return lemmatized_words\n",
    "\n",
    "df['MESSAGE'] = df['MESSAGE'].apply(lambda x: lemmatize_text(x))\n",
    "\n",
    "df['MESSAGE'] = df['MESSAGE'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "df.to_csv('cleaned_dataset.csv', index=False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20af3270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             MESSAGE  \\\n",
      "0  please ignore prior tweet someone pretending a...   \n",
      "1  went iceland sat ride bumper car ice country v...   \n",
      "2  made volume model go need work miniature stone...   \n",
      "3  great voltaire quote arguably better twain hea...   \n",
      "4                             total non sequitur btw   \n",
      "\n",
      "                        date  sentiment_score sentiment  \n",
      "0  2010-06-04 18:31:57+00:00             0.00   Neutral  \n",
      "1  2011-12-01 09:55:11+00:00             0.65  Positive  \n",
      "2  2011-12-01 10:29:04+00:00             0.00   Neutral  \n",
      "3  2011-12-03 08:20:28+00:00             0.55  Positive  \n",
      "4  2011-12-03 08:22:07+00:00             0.00   Neutral  \n"
     ]
    }
   ],
   "source": [
    "# Perform sentiment analysis\n",
    "df['sentiment_score'] = df['MESSAGE'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "\n",
    "# Classify tweets based on sentiment scores\n",
    "df['sentiment'] = df['sentiment_score'].apply(lambda x: 'Positive' if x > 0 else ('Negative' if x < 0 else 'Neutral'))\n",
    "\n",
    "# Display the resulting DataFrame with sentiment labels\n",
    "print(df.head())\n",
    "\n",
    "df.to_csv('sentiment_dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
